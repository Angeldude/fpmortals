#+TITLE: Functional Programming in Scala for Mortals
#+AUTHOR: Sam Halliday
#+DATE: 2017

# https://lakshminp.com/publishing-book-using-org-mode
#+TAGS: ME OTHER
#+TODO: TODO | RESEARCH | NOTES | CHART | DIAGRAM | DRAWING | CODE | VIDEO
#+OPTIONS: toc:nil

* Frontmatter
:PROPERTIES:
:EXPORT_FILE_NAME: frontmatter.md
:END:
{frontmatter}

** About This Book

This book is for Scala developers with an Object Oriented (OOP)
background who wish to learn the *Functional Programming* (FP)
paradigm. We do not accept that the merits of FP are obvious.
Therefore, this book justifies every concept with practical examples,
in Scala.

This book is not aimed at Haskell developers. Such readers will be
frustrated by the Java analogies and will prefer the [[http://typelevel.org/cats/][cats
documentation]].

This book is designed to be read from cover to cover, in the order
presented, with a rest between chapters. A computer is not necessary
to follow along.

If you would like hands-on exercises, we recommend [[https://www.scala-exercises.org/][scala-exercises.org]]

We also recommend [[https://www.manning.com/books/functional-programming-in-scala][The Red Book]] as further reading. It teaches how to
write an FP library in Scala from first principles.

** Copyleft Notice

This book is *Libre* and follows the philosophy of [[https://www.gnu.org/philosophy/free-sw.en.html][Free Software]]: you
can use this book as you like, you can redistribute this book and you
can distribute your own version. That means you can print it,
photocopy it, e-mail it, upload it to websites, change it, translate
it, remix it, delete bits, and draw all over it. You can even sell it,
although you should agree a royalty share with the author or you'll
not be getting an xmas card.

This book is *Copyleft*: if you change the book and distribute your
own version, you must also pass these freedoms to its recipients.

This book uses the [[https://creativecommons.org/licenses/by-sa/4.0/legalcode][Creative Commons Attribution ShareAlike 4.0
International]] (CC BY-SA 4.0) license.

All code samples in this book are separately [[https://www.apache.org/licenses/LICENSE-2.0][Apache 2.0]] licensed,
which is Libre but not Copyleft.

** Thanks

Diego Esteban Alonso Blas, Raúl Raja Martínez and Peter Neyens of 47
degrees for their help with understanding the principles of FP, cats
and freestyle. Yi Lin Wei and Zainab Ali for their tutorials at Hack
The Tower meetups.

Rory Graves and Ani Chakraborty for giving feedback on early drafts of
this text.

Juan Manuel Serrano for [[https://skillsmatter.com/skillscasts/9904-london-scala-march-meetup#video][All Roads Lead to Lambda]], Pere Villega for [[http://perevillega.com/understanding-free-monads][On
Free Monads]], Dick Wall and Josh Suereth for [[https://www.youtube.com/watch?v=WDaw2yXAa50][For: What is it Good For?]],
John de Goes for [[http://degoes.net/articles/easy-monads][A Beginner Friendly Tour]], Erik Bakker for [[https://www.youtube.com/watch?v=hGMndafDcc8][Options in
Futures, how to unsuck them]].

The helpul souls who helped explain the concepts needed to write the
example project [[https://github.com/fommil/drone-dynamic-agents/issues?q=is%3Aissue+is%3Aopen+label%3A%22needs+guru%22][drone-dynamic-agents]]: Merlin Göttlinger, Edmund Noble,
Rob Norris, Adelbert Chang, Kai(luo) Wang, Michael Pilquist, Adam
Chlupacek, Pavel Chlupacek, Paul Snively, Daniel Spiewak.

** Practicalities

If you'd like to set up a project that uses the libraries presented in
this book, you will need to use a recent version of Scala with
FP-specific features enabled (e.g. in =build.sbt=):

#+BEGIN_SRC scala
scalaVersion in ThisBuild := "2.12.2"
scalacOptions in ThisBuild ++= Seq(
  "-language:_",
  "-Ypartial-unification"
)
#+END_SRC

and add the following dependencies to your project's settings:

#+BEGIN_SRC scala
libraryDependencies ++= Seq(
  "io.circe" %% "circe-core",
  "io.circe" %% "circe-generic",
  "io.circe" %% "circe-parser"
).map(_ % "0.7.0") ++ Seq(
  "org.typelevel" %% "cats"     % "0.9.0",
  "com.spinoco"   %% "fs2-http" % "0.1.6"
)

resolvers += Resolver.sonatypeRepo("snapshots")
addCompilerPlugin("org.scalamacros" %  "paradise"  % "2.1.0" cross CrossVersion.full)
libraryDependencies += "com.47deg"  %% "freestyle" % "0.1.0-SNAPSHOT"
#+END_SRC

In order to keep our snippets short, we will omit the =import=
section. Unless told otherwise, assume that all snippets have the
following imports:

#+BEGIN_SRC scala
import cats._
import cats.implicits._
import freestyle._
import freestyle.implicits._
import fs2._
#+END_SRC

* Mainmatter
:PROPERTIES:
:EXPORT_FILE_NAME: mainmatter.md
:END:
{mainmatter}

* Introduction                                                       :sample:
  :PROPERTIES:
  :EXPORT_FILE_NAME: introduction.md
  :END:
** Introduction

It is human instinct to be sceptical of a new paradigm. To put some
perspective on how far we have come, and the shifts we have already
accepted on the JVM, let's start with a quick recap of the last 20
years.

Java 1.2 introduced the Collections API, allowing us to write methods
that abstracted over mutable collections. It was useful for writing
general purpose algorithms and was the bedrock of our codebases.

But there was a problem, we had to perform runtime casting:

#+BEGIN_SRC java
public String first(Collection collection) {
  return (String)(collection.get(0));
}
#+END_SRC

In response, developers defined domain objects in their business logic
that were effectively =CollectionOfThings=, and the Collection API
became implementation detail.

In 2005, Java 5 introduced /generics/, allowing us to define
=Collection<Thing>=, abstracting over the container *and* its
elements. Generics changed how we wrote Java.

The author of the Java generics compiler, Martin Odersky, then created
Scala with a stronger type system, immutable data structures and
multiple inheritance. This brought about a fusion of object oriented
(OOP) and functional programming (FP).

For most developers, FP means using immutable data structures as much
as possible, but mutable state is still a necessary evil that must be
isolated and managed, e.g. with Akka actors or =synchronized= classes.
This style of FP results in simpler programs that are easier to
parallelise and distribute, an improvement over Java. But it is only
scratching the surface of the benefits of FP, as we'll discover in
this book.

Scala also brings =Future=, making it easy to write asynchronous
applications. But when a =Future= makes it into a return type,
/everything/ needs to be rewritten to accomodate it, including the
tests, which are now subject to arbitrary timeouts.

We have a problem similar to Java 1.0: there is no way of abstracting
over execution, much as we had no way of abstracting over collections.

*** Abstracting over Execution

Let's say we want to interact with the user over the command line
interface. We can =read= what the user types and we can =write= a
message to them.

#+BEGIN_SRC scala
trait TerminalSync {
  def read(): String
  def write(t: String): Unit
}

trait TerminalAsync {
  def read(): Future[String]
  def write(t: String): Future[Unit]
}
#+END_SRC

But how do we write generic code that does something as simple as echo
the user's input synchronously or asynchronously depending on our
runtime implementation?

We could write a synchronous version and wrap it with =Future= but now
we have to worry about which thread pool we should be using for the
work, or we could =Await.result= on the =Future= and introduce thread
blocking. In either case, it's a lot of boilerplate and we are
fundamentally dealing with different APIs that are not unified.

Let's try to solve the problem like Java 1.2 by introducing a common
parent. To do this, we need to use the /higher kinded types/ Scala
language feature.

#+BEGIN_ASIDE

*Higher Kinded Types* allow us to use a /type constructor/ in our type
parameters, which looks like =C[_]=. This is a way of saying that
whatever =C= is, it must take a type parameter. For example:

#+BEGIN_SRC scala
trait Foo[C[_]] {
  def create(i: Int): C[Int]
}
#+END_SRC

A type constructor is syntax for a type that takes a type to construct
another type. =List= is a type constructor because it takes a type
(e.g. =Int=) and constructs a type (=List -> Int -> List[Int]=). We
can implement =Foo= using =List=:

#+BEGIN_SRC scala
object FooList extends Foo[List] {
  def create(i: Int): List[Int] = List(i)
}
#+END_SRC

We can also implement =Foo= for anything with a type parameter hole,
e.g. =Either[String, _]=. Unfortunately it is a bit clunky and we have
to create a type alias:

#+BEGIN_SRC scala
type EitherString[T] = Either[String, T]
object FooEitherString extends Foo[EitherString] {
 def create(i: Int): Either[String, Int] = Right(i)
}
#+END_SRC

There is a trick we can use when we want to ignore the type
constructor. Recall that type aliases don't define any new types, they
just use substitution for convenient names. Let's define a type alias
to be equal to its parameter:

#+BEGIN_SRC scala
type Id[T] = T
#+END_SRC

Before proceeding, convince yourself that =Id[Int]= is the same thing
as =Int=, by substituting =Int= into =T=. Since =Id= is a valid type
constructor, so we can use =Id= in an implementation of =Foo=

#+BEGIN_SRC scala
object FooId extends Foo[Id] {
  def create(i: Int): Int = i
}
#+END_SRC

#+END_ASIDE

We want to define =Terminal= for a type constructor =C[_]=. By
defining =Now= to construct to its type parameter (like =Id=), we can
implement a common interface for synchronous and asynchronous
terminals:

#+BEGIN_SRC scala
trait Terminal[C[_]] {
  def read: C[String]
  def write(t: String): C[Unit]
}

type Now[X] = X

object TerminalSync extends Terminal[Now] {
  def read: String = ???
  def write(t: String): Unit = ???
}

object TerminalAsync extends Terminal[Future] {
  def read: Future[String] = ???
  def write(t: String): Future[Unit] = ???
}
#+END_SRC

You can think of =C= as a /Context/ because we say "in the context of
executing =Now=" or "in the =Future=".

But we know nothing about =C= and we can't do anything with a
=C[String]=. What we need is a kind of execution environment that lets
us call a method returning =C[T]= and then be able to do something
with the =T=, including calling another method on =Terminal=. We also
need a way of wrapping a value as a =C[_]=. This signature works well:

#+BEGIN_SRC scala
trait Execution[C[_]] {
  def doAndThen[A, B](c: C[A])(f: A => C[B]): C[B]
  def create[B](b: B): C[B]
}
#+END_SRC

letting us write:

#+BEGIN_SRC scala
def echo[C[_]](t: Terminal[C], e: Execution[C]): C[String] =
  e.doAndThen(t.read) { in: String =>
    e.doAndThen(t.write(in)) { _: Unit =>
      e.create(in)
    }
  }
#+END_SRC

We can now share the =echo= implementation between synchronous and
asynchronous codepaths. We can write a mock implementation of
=Terminal[Now]= and use it in our tests without any timeouts.

Implementations of =Execution[Now]= and =Execution[Future]= are
reusable by generic methods like =echo=. But the code for =echo= is
horrible! Let's clean it up.

The =implicit class= Scala language feature gives =C= some methods.
We'll call these methods =flatMap= and =map= for reasons that will
become clearer in a moment. Each method takes an =implicit
Execution[C]=, but this is nothing more than the =flatMap= and =map=
that you're used to on =Seq=, =Option= and =Future=

#+BEGIN_SRC scala
object Execution {
  implicit class Ops[A, C[_]](c: C[A]) {
    def flatMap[B](f: A => C[B])(implicit e: Execution[C]): C[B] =
          e.doAndThen(c)(f)
    def map[B](f: A => B)(implicit e: Execution[C]): C[B] =
          e.doAndThen(c)(f andThen e.create)
  }
}

def echo[C[_]](implicit t: Terminal[C], e: Execution[C]): C[String] =
  t.read.flatMap { in: String =>
    t.write(in).map { _: Unit =>
      in
    }
  }
#+END_SRC

We can now reveal why we used =flatMap= as the method name: it lets us
use a /for comprehension/, which is just syntax sugar over nested
=flatMap= and =map=.

#+BEGIN_SRC scala
def echo[C[_]](implicit t: Terminal[C], e: Execution[C]): C[String] =
  for {
    in <- t.read
     _ <- t.write(in)
  } yield in
#+END_SRC

Our =Execution= has the same signature as a trait in the cats library
called =Monad= (except =doAndThen= is =flatMap= and =create= is =pure=).
We say that =C= is /monadic/ when there is an implicit =Monad[C]=
available. In addition, cats has the =Id= type alias.

The takeaway is: if we write methods that operate on monadic types,
then we can write sequential code that abstracts over its execution
context. Here, we have shown an abstraction over synchronous and
asynchronous execution but it can also be for the purpose of more
rigorous error handling (where =C[_]= is =Either[Error, _]=), managing
access to volatile state, performing I/O, or auditing of the session.

*** Pure Functional Programming

FP functions have three key properties:

- *Totality* return a value for every possible input
- *Determinism* return the same value for the same input
- *Purity* the only effect is the computation of a return value.

Together, these properties give us an unprecedented ability to reason
about our code. For example, caching is easier to understand with
determinism and purity, and input validation is easier to isolate with
totality.

The kinds of things that break these properties are /side effects/:
accessing or changing mutable state (e.g. generating random numbers,
maintaining a =var= in a class), communicating with external resources
(e.g. files or network lookup), or throwing exceptions.

But in Scala, we perform side effects all the time. A call to
=log.info= will perform I/O and a call to =asString= on a =Http=
instance will speak to a web server. It's fair to say that typical
Scala is *not* FP.

However, something beautiful happened when we wrote our implementation
of =echo=. Anything that depends on state or external resources is
provided as an explicit input: our functions are deterministic and
pure. We not only get to abstract over execution environment, but we
also get to dramatically improve the repeatability - and performance -
of our tests. For example, we are free to implement =Terminal= without
any interactions with a real console.

Of course we cannot write an application devoid of interaction with
the world. In FP we push the code that deals with side effects to the
edges. That kind of code can use battle-tested libraries like NIO,
Akka and Play, isolated away from the core business logic.

This book expands on the FP style introduced in this chapter. We're
going to use the traits and classes defined in the /cats/ and /fs2/
libraries to implement streaming applications. We'll also use the
/freestyle/ and /simulacrum/ developer tooling to eliminate some of
the boilerplate we've already seen in this chapter, allowing you to
focus on writing pure business logic.

* Under Review                                                       :sample:
  :PROPERTIES:
  :EXPORT_FILE_NAME: under-review.md
  :END:
** For Comprehensions

Scala's =for= comprehension is heavily used in FP --- it is the ideal
abstraction for pure sequential code. But most Scala developers only
use =for= to loop over collections and are not aware of its full
potential.

In this chapter, we're going to relearn the principles of =for= and
how cats can help us to write cleaner code. This chapter doesn't try
to write pure programs and the techniques can be immediately applied
to a non-FP codebase.

*** Syntax Sugar

Scala's =for= is just a simple rewrite rule, also called /syntax
sugar/, that doesn't have any contextual information.

To see what a =for= comprehension is doing, we use the =show= and
=reify= feature in the REPL to print out what code looks like after
type inference.

#+BEGIN_SRC scala
scala> import scala.reflect.runtime.universe._
scala> val a, b, c = Option(1)
scala> show { reify {
         for { i <- a ; j <- b ; k <- c } yield (i + j + k)
       } }

res:
$read.a.flatMap(
  ((i) => $read.b.flatMap(
    ((j) => $read.c.map(
      ((k) => i.$plus(j).$plus(k)))))))
#+END_SRC

There is a lot of noise due to additional sugarings (e.g. =+= is
rewritten =$plus=, etc). We'll skip the =show= and =reify= for brevity
when the REPL line is =reify>=, and manually clean up the generated
code so that it doesn't become a distraction.

#+BEGIN_SRC scala
reify> for { i <- a ; j <- b ; k <- c } yield (i + j + k)

a.flatMap {
  i => b.flatMap {
    j => c.map {
      k => i + j + k }}}
#+END_SRC

The rule of thumb is that every =<-= (called a /generator/) is a
nested =flatMap= call, with the final generator a =map= containing the
=yield= body.

**** Assignment

We can assign values inline like =ij = i + j= (a =val= keyword is not
needed).

#+BEGIN_SRC scala
reify> for {
         i <- a
         j <- b
         ij = i + j
         k <- c
       } yield (ij + k)

a.flatMap {
  i => b.map { j => (j, i + j) }.flatMap {
    case (j, ij) => c.map {
      k => ij + k }}}
#+END_SRC

A =map= over the =b= introduces the =ij= which is flat-mapped along
with the =j=, then the final =map= for the code in the =yield=.

Unfortunately we cannot assign before any generators. It has been
requested as a language feature but has not been implemented:
https://github.com/scala/bug/issues/907

#+BEGIN_SRC scala
scala> for {
         initial = getDefault
         i <- a
       } yield initial + i
<console>:1: error: '<-' expected but '=' found.
#+END_SRC

We can workaround the limitation by defining a =val= outside the =for=

#+BEGIN_SRC scala
scala> val initial = getDefault
scala> for { i <- a } yield initial + i
#+END_SRC

or create an =Option= out of the initial assignment

#+BEGIN_SRC scala
scala> for {
         initial <- Option(getDefault)
         i <- a
       } yield initial + i
#+END_SRC

#+BEGIN_ASIDE

=val= doesn't have to assign to a single value, it can be anything
that works as a =case= in a pattern match.

#+BEGIN_SRC scala
scala> val (first, second) = ("hello", "world")
first: String = hello
second: String = world

scala> val list: List[Int] = ...
scala> val head :: tail = list
head: Int = 1
tail: List[Int] = List(2, 3)
#+END_SRC

The same is true for assignment in =for= comprehensions

#+BEGIN_SRC scala
scala> val maybe = Option(("hello", "world"))
scala> for {
         entry <- maybe
         (first, _) = entry
       } yield first
res: Some(hello)
#+END_SRC

But be careful that you don't miss any cases or you'll get a runtime
exception (a /totality/ failure).

#+BEGIN_SRC scala
scala> val a :: tail = list
caught scala.MatchError: List()
#+END_SRC
#+END_ASIDE

**** Filter

It is possible to put =if= statements after a generator to filter
values by a predicate

#+BEGIN_SRC scala
reify> for {
         i  <- a
         j  <- b
         if i > j
         k  <- c
       } yield (i + j + k)

a.flatMap {
  i => b.withFilter {
    j => i > j }.flatMap {
      j => c.map {
        k => i + j + k }}}
#+END_SRC

Older versions of scala used =filter=, but =Traversable.filter=
creates new collections for every predicate, so =withFilter= was
introduced as the more performant alternative.

We can accidentally trigger a =withFilter= by providing type
information: it's actually interpreted as a pattern match.

#+BEGIN_SRC scala
reify> for { i: Int <- a } yield i

a.withFilter {
  case i: Int => true
  case _      => false
}.map { i => i }
#+END_SRC

Like in assignment, a generator can use a pattern match on the left
hand side. But unlike assignment (which throws =MatchError= on
failure), generators are /filtered/ and will not fail at runtime.
However, there is an inefficient double application of the pattern.

**** For Each

Finally, if there is no =yield=, the compiler will use =foreach=
instead of =flatMap=, which is only useful for side-effects.

#+BEGIN_SRC scala
reify> for { i <- a ; j <- b } println(s"$i $j")

a.foreach { i => b.foreach { j => println(s"$i $j") } }
#+END_SRC

**** Summary

The full set of methods supported by =for= comprehensions do not share
a common super type; each generated snippet is independently compiled.
If there were a trait, it would roughly look like:

#+BEGIN_SRC scala
trait ForComprehensible[C[_]] {
  def map[A, B](f: A => B): C[B]
  def flatMap[A, B](f: A => C[B]): C[B]
  def withFilter[A](p: A => Boolean): C[A]
  def foreach[A](f: A => Unit): Unit
}
#+END_SRC

If the context (=C[_]=) of a =for= comprehension doesn't provide its
own =map= and =flatMap=, all is not lost. An implicit
=cats.FlatMap[T]= will provide =map= and =flatMap= for =T= and it can
be the context of a =for= comprehension.

#+BEGIN_ASIDE

It often surprises developers when inline =Future= calculations in a
=for= comprehension do not run in parallel:

#+BEGIN_SRC scala
import scala.concurrent._
import ExecutionContext.Implicits.global

for {
  i <- Future { expensiveCalc() }
  j <- Future { anotherExpensiveCalc() }
} yield (i + j)
#+END_SRC

This is because the =flatMap= spawning =anotherExpensiveCalc= is
strictly *after* =expensiveCalc=. To ensure that two =Future=
calculations begin in parallel, start them outside the =for=
comprehension.

#+BEGIN_SRC scala
val a = Future { expensiveCalc() }
val b = Future { anotherExpensiveCalc() }
for { i <- a ; j <- b } yield (i + j)
#+END_SRC

=for= comprehensions are fundamentally for defining sequential
programs. We will show a far superior way of defining parallel
computations in a later chapter.
#+END_ASIDE

*** Unhappy path

So far we've only look at the rewrite rules, not what is happening in
=map= and =flatMap=. Let's consider what happens when the =for=
context decides that it can't proceed any further.

In the =Option= example, the =yield= is only called when =i,j,k= are
all defined.

#+BEGIN_SRC scala
for {
  i <- a
  j <- b
  k <- c
} yield (i + j + k)
#+END_SRC

If any of =a,b,c= are =None=, the comprehension short-circuits with
=None= but it doesn't tell us what went wrong.

#+BEGIN_ASIDE

How often have you seen a function that takes =Option= parameters but
requires them all to exist? An alternative to throwing a runtime
exception is to use a =for= comprehension, giving us totality (a
return value for every input):

#+BEGIN_SRC scala
def namedThings(
  someName  : Option[String],
  someNumber: Option[Int]
): Option[String] = for {
  name   <- someName
  number <- someNumber
} yield s"$number ${name}s"
#+END_SRC

but this is verbose, clunky and bad style. If a function requires
every input then it should make its requirement explicit, pushing the
responsibility of dealing with optional parameters to its caller ---
don't use =for= unless you need to.
#+END_ASIDE

If we use =Either=, then a =Left= will cause the =for= comprehension
to short circuit with extra information, much better than =Option= for
error reporting:

#+BEGIN_SRC scala
scala> val a = Right(1)
scala> val b = Right(2)
scala> val c: Either[String, Int] = Left("sorry, no c")
scala> for { i <- a ; j <- b ; k <- c } yield (i + j + k)

Left(sorry, no c)
#+END_SRC

And lastly, let's see what happens with a =Future= that fails:

#+BEGIN_SRC scala
scala> import scala.concurrent._
scala> import ExecutionContext.Implicits.global
scala> for {
         i <- Future.failed[Int](new Throwable)
         j <- Future { println("hello") ; 1 }
       } yield (i + j)
scala> Await.result(f, duration.Duration.Inf)
caught java.lang.Throwable
#+END_SRC

The =Future= that prints to the terminal is never called because, like
=Option= and =Either=, the =for= comprehension short circuits.

Short circuiting for the unhappy path is a common and important theme.
=for= comprehensions cannot express resource cleanup: there is no way
to =try= / =finally=. This is good, in FP it puts a clear ownership of
responsibility for unexpected error recovery and resource cleanup onto
the context (which is usually a =Monad= as we'll see later), not the
business logic.

*** Gymnastics

Although it's easy to rewrite simple sequential code as a =for=
comprehension, sometimes we'll want to do something that appears to
require mental summersaults. This section collects some practical
examples and how to deal with them.

**** Fallback Logic

Let's say we are calling out to a method that returns an =Option= and
if it's not successful we want to fallback to another method (and so
on and so on), like when we're using a cache:

#+BEGIN_SRC scala
def getFromRedis(s: String): Option[String]
def getFromSql(s: String): Option[String]

getFromRedis(key) orElse getFromSql(key)
#+END_SRC

If we have to do this for an asynchronous version of the same API

#+BEGIN_SRC scala
def getFromRedis(s: String): Future[Option[String]]
def getFromSql(s: String): Future[Option[String]]
#+END_SRC

then we have to be careful not to do extra work because

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  sql   <- getFromSql(key)
} yield cache orElse sql
#+END_SRC

will run both queries. We can pattern match on the first result but
the type is wrong

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  res   <- cache match {
             case Some(_) => cache !!! wrong type !!!
             case None    => getFromSql(key)
           }
} yield res
#+END_SRC

We need to create a =Future= from the =cache=

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  res   <- cache match {
             case Some(_) => Future.successful(cache)
             case None    => getFromSql(key)
           }
} yield res
#+END_SRC

=Future.successful= creates a new =Future=, much like an =Option= or
=List= constructor.

If functional programming was like this all the time, it'd be a
nightmare. Thankfully these tricky situations are the corner cases.

#+BEGIN_ASIDE

We could code golf it and write

#+BEGIN_SRC scala
getFromRedis(key) orElseM getFromSql(key)
#+END_SRC

by defining https://github.com/typelevel/cats/issues/1625 but it can
be a cognitive burden to remember all these helper methods. The level
of verbosity of a codebase vs code reuse of trivial functions is a
stylistic decision for each team.
#+END_ASIDE

*** Incomprehensible

You may have noticed that the context we're comprehending over must
stay the same: we can't mix contexts.

#+BEGIN_SRC scala
scala> def option: Option[Int] = ...
scala> def future: Future[Int] = ...
scala> for {
         a <- option
         b <- future
       } yield a * b
<console>:23: error: type mismatch;
 found   : Future[Int]
 required: Option[?]
         b <- future
              ^
#+END_SRC

Nothing can help us mix arbitrary contexts in a =for= comprehension,
because the meaning is not well defined.

But when we have nested contexts the intention is usually obvious yet
the compiler still doesn't accept our code.

#+BEGIN_SRC scala
scala> def getA: Future[Option[Int]] = ...
scala> def getB: Future[Option[Int]] = ...
scala> for {
         a <- getA
         b <- getB
       } yield a * b
<console>:30: error: value * is not a member of Option[Int]
       } yield a * b
                 ^
#+END_SRC

Here we want =for= to take care of the outer =Future= and let us write
our code on the inner =Option=. Hiding the outer context is exactly
what a /monad transformer/ does, and cats provides implementations for
=Option=, =Future= and =Either= named =OptionT=, =FutureT= and
=EitherT= respectively.

We create an =OptionT= from each method call. This changes the context
of the =for= into =OptionT[Future, _]=, with =flatMap= and =map=
giving us the value of the =Option=.

Don't forget the import statements from the Practicalities chapter.

#+BEGIN_SRC scala
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
       } yield a * b
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

The outer context can be anything that normally works in a =for=
comprehension, but it needs to stay the same throughout. Call =.value=
to return to it.

#+BEGIN_SRC scala
scala> result.value
res: Future[Option[Int]] = Future(<not completed>)
#+END_SRC

The monad transformer also allows us to mix =Future[Option[_]]= calls
with methods that just return plain =Future= via =OptionT.liftF=

#+BEGIN_SRC scala
scala> def getC: Future[Int] = ...
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
         c <- OptionT.liftF(getC)
       } yield a * b / c
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

and we can mix with methods that return plain =Option= by wrapping
them in =Future.successful= followed by =OptionT=

#+BEGIN_SRC scala
scala> def getD: Option[Int] = ...
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
         c <- OptionT.liftF(getC)
         d <- OptionT(Future.successful(getD))
       } yield (a * b) / (c * d)
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

It's gotten messy again, but it's still better than writing nested
=flatMap= and =map=. A way to clean this up is to define a DSL that
handles all the required conversions into =OptionT[Future, _]=

#+BEGIN_SRC scala
object Lift {
  type C[T] = OptionT[Future, T]
  def $[T](f: Future[T]): C[T] = OptionT.liftF(f)
  def $[T](t: Option[T]): C[T] = OptionT(Future.successful(t))
  def $[T](t: T): C[T]         = $(Some(t))
}
#+END_SRC

Unfortunately, due to runtime erasure we cannot also have a =$= method
for =Future[Option[T]]= because the bytecode signature would clash
with =Future[T]= giving
=$(Lscala/concurrent/Future;)cats.data.OptionT=.

#+BEGIN_SRC scala
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
         c <- Lift $  getC
         d <- Lift $  getD
         e <- Lift $  10
       } yield e * (a * b) / (c * d)
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

If you don't like the lifting being on the left, or the method
overloading, you can define a different DSL with explicit transformer
creation on the right

#+BEGIN_SRC scala
implicit class Ops[In](in: In) {
  def |>[Out](f: In => Out): Out = f(in)
}
def liftFutureOption[T](f: Future[Option[T]]) = OptionT(f)
def liftFuture[T](f: Future[T]) = OptionT.liftF(f)
def liftOption[T](t: Option[T]) = OptionT(Future.successful(t))
def lift[T](t: T)               = liftOption(Some(t))
#+END_SRC

which has a clearer visual separation of the logic from the ugly
transformations (they almost look like comments)

#+BEGIN_SRC scala
scala> val result = for {
         a <- getA       |> liftFutureOption
         b <- getB       |> liftFutureOption
         c <- getC       |> liftFuture
         d <- getD       |> liftOption
         e <- 10         |> lift
       } yield e * (a * b) / (c * d)
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

This approach also works for =EitherT= and =FutureT= as the inner
context, but their lifting methods are more complex as they require
parameters to construct the =Left= and an implicit =ExecutionContext=
respectively. cats provides monad transformers for a lot of its own
types, so it's worth checking if one is available.

Notably absent is =ListT= (or =TraversableT=) because it is difficult
to create a well-behaved monad transformer for collections. It comes
down to the unfortunate fact that grouping of the operations can
unintentionally reorder =flatMap= calls. [[https://github.com/typelevel/cats/issues/977][cats ticket #977]] aims to
implement =ListT=. Implementing a monad transformer is an advanced
topic.

* Main Text
  :PROPERTIES:
  :EXPORT_FILE_NAME: main-text.md
  :END:
** TODO Implicits

Perhaps need a refresher on how implicits work.

** TODO Example

Just the high level concepts. Ask the reader to suspend their belief
of =@free= and we'll explain what it's doing later, plus the algebraic
mixing.

And an =Id= based test to show that we can really write business logic
tests without a real implementation.

An architect's dream: you can focus on algebras, business logic and
functional requirements, and delegate the implementations to your
teams.

** TODO Pure business logic

(the cross-over from previous section is not yet clear)

We can define things that are like Java =interface=s, but with the
container and its implementation abstracted away, called an Algebra.

We can write all our business logic solely by combining these
algebras. If you ever want to call some code that can throw an
exception or speaks to the outside world, wrap it in an algebra so it
can be abstracted.

Everything can now be mocked, and we can write tests just of the
business logic.

Include some thoughts from [[http://degoes.net/articles/easy-monads][Beginner Friendly Tour]]

** RESEARCH Parallel work

Generating the initial state and https://github.com/fommil/drone-dynamic-agents/issues/6

Might require a moment to explain =FreeApplicative= (I'd rather not get into details yet).

** TODO Reality Check

- solved initial abstraction problem
- clean way to write logic and divide labour
- easier to write maintainable and testable code

Three steps forward but two steps back: performance, IDE support.

High level overview of what =@free= and =@module= is doing, and the
concept of trampolining. For a detailed explanation of free style and
the cats free monad implementation, see the appendix.

*** RESEARCH perf numbers
** TODO Typeclasses

look into the oauth / google / drone algebras as examples.

how cats uses typeclasses, e.g. to provide the =flatMap= on the free
monad and =|+|= on applicatives.

Discourage hierarchies except for ADTs

** TODO Cats
*** RESEARCH typeclasses

Foldable being imminently more interesting than the others.

Traversable will need to be discussed, seems to come up a lot.

Use (impure) example of merging two deep configuration ADTs (scala
does not enforce purity so we can choose our own level)

Not enough to implement, must also pass the laws

Maybe use this example? https://gitter.im/typelevel/cats?at=5904a2e98bb56c2d11f53979

#+BEGIN_SRC scala
@ class Lift[F[_]] {
    def $[A](fa: F[Option[A]]): OptionT[F,A] = OptionT(fa)
    def $[A](opt: Option[A])(implicit F: Applicative[F]): OptionT[F,A] = OptionT(F.pure(opt))
    def $[A](a: A)(implicit F: Applicative[F]): OptionT[F,A] = OptionT(F.pure(Some(a)))
  }
defined class Lift
@ def liftFrom[F[_]] = new Lift[F] {}
defined function liftFrom
@ val lift = liftFrom[List]
lift: Lift[List] = $sess.cmd26$$anon$1@6cf3d7c8
@ val prg = for {
    x <- lift $ 1
    y <- lift $ Option(2)
    z <- lift $ List(Some(3), Some(4))
  } yield x + y + z
prg: OptionT[List, Int] = OptionT(List(Some(6), Some(7)))
#+END_SRC

*** RESEARCH data types

Not really sure what to say here.

** TODO Spotting patterns, refactoring

Note that some of our algebras are actually common things and can be
rewritten: reader / writer / state / error / indexed monad. It's ok
that this is a step you can do later.

These are called Effects.

** CODE FS2 Streams

The basics, and covering the Effect, which can be our free monad.

Why streams are so awesome. I'd like a simple example here of reading
from a huge data source, doing parallel work and then writing out in
order to a (slower) device to demonstrate backpressure and constant
memory overhead. Maybe compare this vs hand rolled and akka streams
for a perf test?

Rewrite our business logic to be streaming, convert our GET api into a
=Stream= by polling.

** TODO interpreters

Show that although interpreters can be as messy as you like, you can
continue to write them as a pure core with side effects pushed to the
outside.

** TODO type refinement

instead of needing those =error= calls in the first place, just don't
allow them to happen at your layer if you can get away with it.

Protect yourself from mistyping

** RESEARCH Optics

not sure what the relevance to this project would be yet.

* Backmatter
:PROPERTIES:
:EXPORT_FILE_NAME: backmatter.md
:END:
{backmatter}
** TODO Free Implementation

detailed explanation about what =@free= / =@module= is generating and
how that feeds into the cats =Free= implementation.
** RESEARCH Tagless Final
